# -*- coding: utf-8 -*-
"""P2_MarketSegmentaion.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lZ9M3bSYWJaZPCI_Repw5G7KXCDJrwMw
"""

from google.colab import drive
drive.mount('/content/gdrive')

!pip install bioinfokit

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from yellowbrick.cluster import KElbowVisualizer
pd.options.mode.chained_assignment = None  # 'warn' or 'raise'
from bioinfokit.visuz import cluster
from sklearn.decomposition import PCA

#DATASET IMPORT---STEP 3
data = pd.read_csv("gdrive/My Drive/mcdonalds_dataset.csv")
data.head()

# CHECKING DATA FOR PREPROCESSING
data.info()

colors1=['lightcoral', 'lightskyblue', 'lightgreen', 'lightpink']
colors2=sns.color_palette("pastel")
#DISTINGUISHING DATA BASED ON CERTAIN FACTORS AND GETTING A DISTRIBUTION OF AGE

def eda(data):
    # Get the list of column names
    data_heads = list(data.columns)

    def plot_binary_attribute_percentage(attribute_name):
        freq = data[attribute_name].value_counts(normalize=True) * 100
        plt.pie(freq, labels=freq.index, autopct='%0.2f',colors=colors1)
        plt.title(f'{attribute_name} Frequency')

    # Plot binary attribute percentages for 'yummy', 'spicy', 'healthy'
    plt.figure(figsize=(12, 12))
    for i, attribute in enumerate(['yummy', 'spicy', 'healthy']):
        plt.subplot(2, 2, i + 1)
        plot_binary_attribute_percentage(attribute)

    # Plot gender ratio
    gender_freq = data['Gender'].value_counts(normalize=True) * 100
    plt.subplot(2, 2, 4)
    plt.pie(gender_freq, labels=gender_freq.index, autopct='%0.2f',explode=[0,0.1],shadow=True, colors=colors2)
    plt.title('Gender Ratio')

    plt.figure(figsize=(12, 12))
    for i, attribute in enumerate(['cheap', 'tasty', 'fast']):
        plt.subplot(2, 2, i + 1)
        plot_binary_attribute_percentage(attribute)

    plt.tight_layout()
    plt.show()

    # Categorize ages and create a bar plot
    age_categories = ["Under 18", "19-30", "31-45", "Above 45"]
    category_counts = [0, 0, 0, 0]

    for age in data['Age']:
        if age < 18:
            category_counts[0] += 1
        elif 19 <= age <= 30:
            category_counts[1] += 1
        elif 31 <= age <= 45:
            category_counts[2] += 1
        else:
            category_counts[3] += 1

    plt.figure(figsize=(8, 6))
    plt.bar(age_categories, category_counts, color='skyblue')
    plt.xlabel('Age Group')
    plt.ylabel('Count')
    plt.title('Ages ')
    plt.show()

    # Plot age distribution
    plt.figure(figsize=(8, 6))
    sns.histplot(data=data, x='Age', bins=20)
    plt.title('Distribution of Age')
    plt.show()

eda(data)

selected_columns = ['Age', 'healthy', 'cheap', 'Gender', 'yummy']
data_subset = data[selected_columns]

#ENCODING FOR ANALYSIS
data_subset['healthy'] = data_subset['healthy'].apply(lambda x: 1 if x.lower() == 'yes' else 0)
data_subset['cheap'] = data_subset['cheap'].apply(lambda x: 1 if x.lower() == 'yes' else 0)
data_subset['Gender'] = data_subset['Gender'].apply(lambda x: 1 if x.lower() == 'male' else 0)
data_subset['yummy'] = data_subset['yummy'].apply(lambda x: 1 if x.lower() == 'yes' else 0)


correlation_matrix = data_subset.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='vlag')
plt.title('Correlation Heatmap')
plt.show()

#MORE EXPLORATION BASED ON LIKES, VISITS AND AGE VS DISGUST, TASY
like_counts = data['Like'].value_counts()
print (like_counts)
plt.figure(figsize=(10, 6))
like_counts.plot(kind='bar', color='purple')
plt.xlabel('Like')
plt.ylabel('Count')
plt.title('Frequency of "Like" ')
plt.xticks(rotation=40, ha='right')  # Rotate x-axis labels for better visibility
plt.tight_layout()
plt.show()\


visit_counts = data['VisitFrequency'].value_counts()
print (visit_counts)
plt.figure(figsize=(10, 6))
visit_counts.plot(kind='bar', color='pink')
plt.xlabel('Like')
plt.ylabel('Count')
plt.title('Categorization of "Visits" ')
plt.xticks(rotation=30, ha='right')
plt.tight_layout()
plt.show()

df = pd.DataFrame(data)

plt.figure(figsize=(10, 5))
sns.histplot(data=df, x='Age', hue='disgusting', bins=10, kde=True)
plt.title('Histogram: Age vs. Disgusting')
plt.xlabel('Age')
plt.show()

plt.figure(figsize=(10, 5))
sns.histplot(data=df, x='Age', hue='tasty', bins=10, kde=True)
plt.title('Histogram: Age vs. Disgusting')
plt.xlabel('Age')
plt.show()

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.decomposition import PCA

df_binary = data.copy()
df_encoded= (df_binary.drop(['Like','Age','VisitFrequency','Gender'],axis=1))
df_encoded

#FOR PRINCIPAL COMPONENT ANALYSIS
label_encoder = LabelEncoder()

for column in df_encoded.columns:
    if df_encoded[column].dtype == 'object':
        df_encoded[column] = label_encoder.fit_transform(df_encoded[column])
print (df_encoded)
scaler = StandardScaler()
standardized_data = scaler.fit_transform(df_encoded)

pca = PCA(n_components=11)
pca.fit(standardized_data)

#Here, I have encoded the binary values as 1/0 and scaled it to fit better into the PCA analyser.

principal_components = pca.transform(standardized_data)
names = ['pc1','pc2','pc3','pc4','pc5','pc6','pc7','pc8','pc9','pc10','pc11']
pf = pd.DataFrame(data = principal_components, columns = names)
print (pf.head(),'\n')

#This gives us a sense of which attributes are relevant.
print (pca.explained_variance_ratio_)

loadings_matrix = pca.components_.T

#The loadings indicate how the original variables are combined to form principal components.
loadings = pca.components_
loadings_df = pd.DataFrame(loadings_matrix, columns=names, index=df_encoded.columns)

print("Loadings Matrix:")
print(loadings_df)

explained_variance_ratios = pca.explained_variance_ratio_
print("\nExplained Variance Ratios:")
print(explained_variance_ratios)

plt.rcParams['figure.figsize'] = (20,15)
ax = sns.heatmap(loadings_df, annot=True, cmap='crest')
plt.show()

pca_scores = PCA().fit_transform(standardized_data)
print (pca_scores)

#IN THE REPORT, A BIPLOT HAS MENTIONED THE ROLE OF CHEAP, EXPENSIVE FEATURES.
plt.figure(figsize=(10, 5))
plt.scatter(pca_scores[:, 0], pca_scores[:, 1], alpha=0.7, color='pink')

for i, variable in enumerate(df_encoded.columns.values):
    plt.arrow(0, 0, loadings[0, i]*4.5, loadings[1, i]*4.5, color='blue', alpha=0.7)
    plt.text(loadings[0, i] * 4.55, loadings[1, i] * 4.55, variable, color='blue')
#Using arrows and scatterplot to create a biplot.
plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.2f}%)')
plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.2f}%)')
plt.title('Biplot (PCA Scores and Loadings)')

plt.grid()
plt.show()

#STEP 5---EXTRACTING SEGMENTS
model=KMeans(n_init='auto')
visualizer = KElbowVisualizer(model, k=(1,12)).fit(df_encoded)
visualizer.show()

from collections import Counter
#USING K-MEANS WITH THE RESULTED ELBOW METHOD NUMBER OF CLUSTERS
kmeans = KMeans(n_clusters=4, init='k-means++', random_state=0).fit(df_encoded)
df_encoded['cluster_num'] = kmeans.labels_
data['cluster_num'] = kmeans.labels_
print('Cluster size: ', Counter(kmeans.labels_))

#VISUALISING CLUSTERS
sns.scatterplot(data=pf, x="pc1", y="pc2", hue=kmeans.labels_)
plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], marker="X", c="r", s=80, label="centroids",cmap='warmcolor')
plt.legend()
plt.show()

#STUDYING THE MARKET SEGMENTS
def compare_cluster(cluster_num):
    cluster_data = df[df_encoded['cluster_num'] == cluster_num]

    plt.figure(figsize=(12, 8))

    # Subplot 1: 'yummy' comparison
    plt.subplot(2, 2, 1)
    sns.countplot(x='yummy', data=cluster_data)
    plt.xlabel('Yummy')
    plt.title(f'Yummy Comparison for Cluster {cluster_num}')

    # Subplot 2: 'healthy' comparison
    plt.subplot(2, 2, 2)
    sns.countplot(x='healthy', data=cluster_data)
    plt.xlabel('Healthy')
    plt.title(f'Healthy Comparison for Cluster {cluster_num}')

    # Subplot 3: 'cheap' comparison
    plt.subplot(2, 2, 3)
    sns.countplot(x='cheap', data=cluster_data)
    plt.xlabel('Cheap')
    plt.title(f'Cheap Comparison for Cluster {cluster_num}')

    # Subplot 4: 'fast' comparison
    plt.subplot(2, 2, 4)
    sns.countplot(x='fast',  data=cluster_data)
    plt.xlabel('Fast')
    plt.title(f'Fast Comparison for Cluster {cluster_num}')

    plt.tight_layout()
    plt.show()
for cluster in range(4):
    compare_cluster(cluster)

#STEP 6---PROFILING SEGMENTS
features = ['yummy', 'healthy', 'cheap', 'fast','greasy','disgusting','tasty','spicy']

import random
palette_names = sns.color_palette().as_hex()

counts = {}
for feature in features:
    counts[feature] = [df[df_encoded['cluster_num'] == i][feature].eq('Yes').sum() for i in range(4)]

#COMPARING EACH FEATURE
plt.figure(figsize=(20, 6))
bar_width = 0.1
cluster_labels = [f'Cluster {i}' for i in range(4)]
colors=['pink','blue','purple','turquoise']
for i, feature in enumerate(features):
    x = [j + i * bar_width for j in range(4)]
    plt.bar(x, counts[feature], width=bar_width, label=feature,color=random.choice(palette_names))

plt.xlabel('Clusters')
plt.ylabel('Count of "Yes"')
plt.xticks([j + bar_width for j in range(4)], cluster_labels)
plt.title('Comparison of "Yes" Count for Different Features in Each Cluster')
plt.legend()
plt.show()

#AGE DISTRIBUTION IN EACH SEGMENT
sns.violinplot(x='cluster_num', y='Age', data=data)
#Box plot hybrid.

#STEP 7---DESCRIBE THE SEGMENTS

from statsmodels.graphics.mosaicplot import mosaic
clusters=[0,1,2,3]
#MOSAIC PLOT FOR GENDER RATIO IN EACH CLUSTER
#Creating a contingency table of Cluster-Nums and Gender
crosstab_gender = pd.crosstab(data['cluster_num'], data['Gender'])

# Plot mosaic plot
plt.rcParams['figure.figsize'] = (7, 5)
mosaic(crosstab_gender.stack())
plt.show()

features = ['Like', 'VisitFrequency']

# Create separate bar plots for each feature within each cluster
for cluster in np.sort(clusters):
    plt.figure(figsize=(16, 12))
    plt.suptitle(f'Cluster {cluster} Feature Distributions', fontsize=16)
    for i, feature in enumerate(features):
        plt.subplot(2, 2, i + 1)  # Adjust the number of rows and columns as needed
        sns.countplot(data=df[df_encoded['cluster_num'] == cluster], x=feature)
        plt.title(feature)
        plt.xlabel('')
        plt.ylabel('')
    plt.tight_layout()
    plt.show()

#STEP 8---SELECTING TARGET SEGMENTS

#We can calculate the mean for each, Age, Like, Gender and VisitFrequency to converge them into one xomparative plot.
data['VisitFrequency'],data['Like'],data['Gender'] = LabelEncoder().fit_transform(df['VisitFrequency']),LabelEncoder().fit_transform(df['Like']),LabelEncoder().fit_transform(df['Gender'])
visits=data.groupby('cluster_num')['VisitFrequency'].mean()
likes=data.groupby('cluster_num')['Like'].mean()
gens=data.groupby('cluster_num')['Gender'].mean()
print (visits)
print (likes)
print (gens)

visits_df = pd.DataFrame({'cluster_num': visits.index, 'VisitFrequency': visits.values})
likes_df = pd.DataFrame({'cluster_num': likes.index, 'Like': likes.values})
gens_df = pd.DataFrame({'cluster_num': gens.index, 'Gender': gens.values})

#PLOTTING ON ONE GRAPH
combined_df = visits_df.merge(likes_df, on='cluster_num').merge(gens_df, on='cluster_num')
plt.figure(figsize = (8,4))
sns.scatterplot(x = "VisitFrequency", y = "Like",data=combined_df,s=300, color="pink")
plt.title("Simple segment evaluation plot.", fontsize = 12)
plt.xlabel("Visit", fontsize = 12)
plt.ylabel("Like", fontsize = 12)
plt.show()